{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVraWpDTW8i0"
   },
   "source": [
    "# Output Parsers for LLM Input / Output with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1KvMtf54l0d"
   },
   "source": [
    "## Install OpenAI, HuggingFace and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xG45p4vhBS0f",
    "outputId": "8d976e2e-56c5-4df0-8a5c-7cdd83708ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.21\n",
      "  Downloading langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.21) (0.3.45)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain==0.3.21)\n",
      "  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.21) (0.3.15)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.21) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.21) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.21) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.21) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain==0.3.21) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain==0.3.21) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain==0.3.21) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain==0.3.21) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.21) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.21) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.21) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.21) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.21) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.21) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.21) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.21) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.21) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.21) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.21) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.21) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.21) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.21) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain==0.3.21) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain==0.3.21) (1.3.1)\n",
      "Downloading langchain-0.3.21-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: langchain-text-splitters, langchain\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.6\n",
      "    Uninstalling langchain-text-splitters-0.3.6:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.6\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.20\n",
      "    Uninstalling langchain-0.3.20:\n",
      "      Successfully uninstalled langchain-0.3.20\n",
      "Successfully installed langchain-0.3.21 langchain-text-splitters-0.3.7\n",
      "Collecting langchain-openai==0.3.9\n",
      "  Downloading langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.3.9) (0.3.45)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.66.3 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.3.9) (1.66.3)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.3.9)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-openai==0.3.9) (0.3.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-openai==0.3.9) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-openai==0.3.9) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-openai==0.3.9) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-openai==0.3.9) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-openai==0.3.9) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-openai==0.3.9) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain-openai==0.3.9) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain-openai==0.3.9) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain-openai==0.3.9) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain-openai==0.3.9) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain-openai==0.3.9) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.66.3->langchain-openai==0.3.9) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.9) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.9) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.66.3->langchain-openai==0.3.9) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.66.3->langchain-openai==0.3.9) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.66.3->langchain-openai==0.3.9) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.66.3->langchain-openai==0.3.9) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-openai==0.3.9) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-openai==0.3.9) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-openai==0.3.9) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-openai==0.3.9) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.45->langchain-openai==0.3.9) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.45->langchain-openai==0.3.9) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.3.9) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.3.9) (2.3.0)\n",
      "Downloading langchain_openai-0.3.9-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
      "Successfully installed langchain-openai-0.3.9 tiktoken-0.9.0\n",
      "Collecting langchain-community==0.3.19\n",
      "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (0.3.45)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (0.3.21)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (9.0.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.19)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.19)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (0.3.15)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community==0.3.19)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.19) (2.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.19) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.19)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.19)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community==0.3.19) (0.3.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community==0.3.19) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community==0.3.19) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community==0.3.19) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community==0.3.19) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.19)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.19) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.19) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.19) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.19) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.19) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain-community==0.3.19) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community==0.3.19) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community==0.3.19) (2.27.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.19)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.19) (1.3.1)\n",
      "Downloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.19 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "# Updated package versions as in previous notebooks\n",
    "# Ensures consistent dependencies across the module\n",
    "!pip install langchain==0.3.21\n",
    "!pip install langchain-openai==0.3.9\n",
    "!pip install langchain-community==0.3.19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtBa7rlWJWH3"
   },
   "source": [
    "## Enter API Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6RD7As2sm8G"
   },
   "source": [
    "#### Enter your Open AI Key here\n",
    "\n",
    "You can get the key from [here](https://platform.openai.com/api-keys) after creating an account or signing in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ogxBkS6ZnnC",
    "outputId": "1889cc11-f4ec-46a7-ebcc-de4195ad20ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your Open AI API Key here: ··········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Please enter your Open AI API Key here: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5rOqCyianbP"
   },
   "source": [
    "## Setup necessary system environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PIStD04Zp9p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4h0xywyJ3v7"
   },
   "source": [
    "## Chat Models and LLMs\n",
    "\n",
    "Large Language Models (LLMs) are a core component of LangChain. LangChain does not implement or build its own LLMs. It provides a standard API for interacting with almost every LLM out there.\n",
    "\n",
    "There are lots of LLM providers (OpenAI, Hugging Face, etc) - the LLM class is designed to provide a standard interface for all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSdF6_R7J45Z"
   },
   "source": [
    "## Accessing Commercial LLMs like ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8nnrOGxZ2uZ"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cei3lVfHduK"
   },
   "source": [
    "## Output Parsers\n",
    "Output parsers are essential in Langchain for structuring the responses from language models. Below, we will discuss the role of output parsers and include examples using Langchain's specific parser types: PydanticOutputParser, JsonOutputParser, and CommaSeparatedListOutputParser.\n",
    "\n",
    "- **Pydantic parser:**\n",
    "  - This parser allows the specification of an arbitrary Pydantic Model to query LLMs for outputs matching that schema. Pydantic's BaseModel functions similarly to a Python dataclass but includes type checking and coercion.\n",
    "\n",
    "- **JSON parser:**\n",
    "  - Users can specify an arbitrary JSON schema with this parser to ensure outputs from LLMs adhere to that schema. Pydantic can also be used to declare your data model here.\n",
    "\n",
    "- **CSV parser:**\n",
    "  - Useful for outputs requiring a list of items separated by commas. This parser facilitates the extraction of comma-separated values from model outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1-PDxOf1h87"
   },
   "source": [
    "### PydanticOutputParser\n",
    "\n",
    "This output parser allows users to specify an arbitrary Pydantic Model and query LLMs for outputs that conform to that schema.\n",
    "\n",
    "Keep in mind that large language models are non-deterministic! You'll have to use an LLM with sufficient capacity to generate well-formed responses.\n",
    "\n",
    "Use Pydantic to declare your data model. Pydantic's BaseModel is like a Python dataclass, but with actual type checking + coercion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fApMfO9zG4B",
    "outputId": "84316138-cb88-43ce-84b8-f544040884c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PydanticOutputParser(pydantic_object=<class '__main__.QueryResponse'>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updated import paths for prompt templates - using simplified paths:\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define your desired data structure - like a python data class.\n",
    "class QueryResponse(BaseModel):\n",
    "    description: str = Field(description=\"A brief description of the topic asked by the user\")\n",
    "    pros: str = Field(description=\"3 bullet points showing the pros of the topic asked by the user\")\n",
    "    cons: str = Field(description=\"3 bullet points showing the cons of the topic asked by the user\")\n",
    "    conclusion: str = Field(description=\"One line conclusion of the topic asked by the user\")\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=QueryResponse)\n",
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iu_4ogkz0ABZ",
    "outputId": "87a3fd2a-9724-4f23-c007-1de7f36cf4bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"description\": {\"description\": \"A brief description of the topic asked by the user\", \"title\": \"Description\", \"type\": \"string\"}, \"pros\": {\"description\": \"3 bullet points showing the pros of the topic asked by the user\", \"title\": \"Pros\", \"type\": \"string\"}, \"cons\": {\"description\": \"3 bullet points showing the cons of the topic asked by the user\", \"title\": \"Cons\", \"type\": \"string\"}, \"conclusion\": {\"description\": \"One line conclusion of the topic asked by the user\", \"title\": \"Conclusion\", \"type\": \"string\"}}, \"required\": [\"description\", \"pros\", \"cons\", \"conclusion\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# langchain pre-generated output response formatting instructions\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIrCkknp0FiO",
    "outputId": "2270c018-e92f-48e2-96dd-9850d5214db6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"description\": {\"description\": \"A brief description of the topic asked by the user\", \"title\": \"Description\", \"type\": \"string\"}, \"pros\": {\"description\": \"3 bullet points showing the pros of the topic asked by the user\", \"title\": \"Pros\", \"type\": \"string\"}, \"cons\": {\"description\": \"3 bullet points showing the cons of the topic asked by the user\", \"title\": \"Cons\", \"type\": \"string\"}, \"conclusion\": {\"description\": \"One line conclusion of the topic asked by the user\", \"title\": \"Conclusion\", \"type\": \"string\"}}, \"required\": [\"description\", \"pros\", \"cons\", \"conclusion\"]}\\n```'}, template='\\n             Answer the user query and generate the response based on the following formatting instructions\\n\\n             Format Instructions:\\n             {format_instructions}\\n\\n             Query:\\n             {query}\\n            ')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the final prompt with formatting instructions from the parser\n",
    "prompt_txt = \"\"\"\n",
    "             Answer the user query and generate the response based on the following formatting instructions\n",
    "\n",
    "             Format Instructions:\n",
    "             {format_instructions}\n",
    "\n",
    "             Query:\n",
    "             {query}\n",
    "            \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_txt,\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pCdfUpn0mdg"
   },
   "outputs": [],
   "source": [
    "# create a simple LCEL chain to take the prompt, pass it to the LLM, enforce response format using the parser\n",
    "chain = (prompt\n",
    "           |\n",
    "         chatgpt\n",
    "           |\n",
    "         parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqYCylpw0u4L"
   },
   "outputs": [],
   "source": [
    "question = \"Tell me about Commercial Real Estate\"\n",
    "response = chain.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZfLIwllb02ax",
    "outputId": "f5376677-d3fb-4493-a6d7-78ca734ae492"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryResponse(description='Commercial real estate refers to properties used exclusively for business purposes, including office buildings, retail spaces, warehouses, and industrial properties.', pros='1. Potential for high returns on investment.\\n2. Long-term leases provide stable income.\\n3. Diversification of investment portfolio.', cons='1. Requires significant capital investment.\\n2. Market fluctuations can impact property values.\\n3. Management and maintenance can be complex and time-consuming.', conclusion='Commercial real estate can be a lucrative investment but comes with its own set of challenges.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "As6-VKZE1W7z",
    "outputId": "c99b766b-31e0-4265-b9d5-000c93e7fe5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Commercial real estate refers to properties used exclusively for business purposes, including office buildings, retail spaces, warehouses, and industrial properties.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8rv_tK00_T-",
    "outputId": "e25da03a-934a-44b2-f0dc-bcc7a87e57ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Commercial real estate refers to properties used exclusively for business purposes, including office buildings, retail spaces, warehouses, and industrial properties.',\n",
       " 'pros': '1. Potential for high returns on investment.\\n2. Long-term leases provide stable income.\\n3. Diversification of investment portfolio.',\n",
       " 'cons': '1. Requires significant capital investment.\\n2. Market fluctuations can impact property values.\\n3. Management and maintenance can be complex and time-consuming.',\n",
       " 'conclusion': 'Commercial real estate can be a lucrative investment but comes with its own set of challenges.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McK3BVa91CH8",
    "outputId": "f79a2417-a0e3-46ec-8786-80f71d9d59ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description:\n",
      "Commercial real estate refers to properties used exclusively for business purposes, including office buildings, retail spaces, warehouses, and industrial properties.\n",
      "\n",
      "pros:\n",
      "1. Potential for high returns on investment.\n",
      "2. Long-term leases provide stable income.\n",
      "3. Diversification of investment portfolio.\n",
      "\n",
      "cons:\n",
      "1. Requires significant capital investment.\n",
      "2. Market fluctuations can impact property values.\n",
      "3. Management and maintenance can be complex and time-consuming.\n",
      "\n",
      "conclusion:\n",
      "Commercial real estate can be a lucrative investment but comes with its own set of challenges.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in response.dict().items():\n",
    "    print(f\"{k}:\\n{v}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMbwJySEITJy"
   },
   "source": [
    "### JsonOutputParser\n",
    "\n",
    "This output parser allows users to specify an arbitrary JSON schema and query LLMs for outputs that conform to that schema.\n",
    "\n",
    "Keep in mind that large language models are non-deterministic! You'll have to use an LLM with sufficient capacity to generate well-formed responses.\n",
    "\n",
    "It is recommended use Pydantic to declare your data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Td0hVmQd3OVw",
    "outputId": "ae36ea67-6651-4582-acc6-7705f5dfa9af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JsonOutputParser(pydantic_object=<class '__main__.QueryResponse'>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "# Updated import paths for prompt templates - using simplified paths:\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "# Define your desired data structure - like a python data class.\n",
    "class QueryResponse(BaseModel):\n",
    "    description: str = Field(description=\"A brief description of the topic asked by the user\")\n",
    "    pros: str = Field(description=\"3 bullet points showing the pros of the topic asked by the user\")\n",
    "    cons: str = Field(description=\"3 bullet points showing the cons of the topic asked by the user\")\n",
    "    conclusion: str = Field(description=\"One line conclusion of the topic asked by the user\")\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=QueryResponse)\n",
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HJvSevb4XES",
    "outputId": "54ae4c0f-6137-40d2-9b64-a93f500e4ceb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"description\": {\"description\": \"A brief description of the topic asked by the user\", \"title\": \"Description\", \"type\": \"string\"}, \"pros\": {\"description\": \"3 bullet points showing the pros of the topic asked by the user\", \"title\": \"Pros\", \"type\": \"string\"}, \"cons\": {\"description\": \"3 bullet points showing the cons of the topic asked by the user\", \"title\": \"Cons\", \"type\": \"string\"}, \"conclusion\": {\"description\": \"One line conclusion of the topic asked by the user\", \"title\": \"Conclusion\", \"type\": \"string\"}}, \"required\": [\"description\", \"pros\", \"cons\", \"conclusion\"]}\\n```'}, template='\\n             Answer the user query and generate the response based on the following formatting instructions\\n\\n             Format Instructions:\\n             {format_instructions}\\n\\n             Query:\\n             {query}\\n            ')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the final prompt with formatting instructions from the parser\n",
    "prompt_txt = \"\"\"\n",
    "             Answer the user query and generate the response based on the following formatting instructions\n",
    "\n",
    "             Format Instructions:\n",
    "             {format_instructions}\n",
    "\n",
    "             Query:\n",
    "             {query}\n",
    "            \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_txt,\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ObjYJrXh8Hj3",
    "outputId": "cc70ef62-8895-466e-96d4-82a1e90d9b9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"description\": {\"description\": \"A brief description of the topic asked by the user\", \"title\": \"Description\", \"type\": \"string\"}, \"pros\": {\"description\": \"3 bullet points showing the pros of the topic asked by the user\", \"title\": \"Pros\", \"type\": \"string\"}, \"cons\": {\"description\": \"3 bullet points showing the cons of the topic asked by the user\", \"title\": \"Cons\", \"type\": \"string\"}, \"conclusion\": {\"description\": \"One line conclusion of the topic asked by the user\", \"title\": \"Conclusion\", \"type\": \"string\"}}, \"required\": [\"description\", \"pros\", \"cons\", \"conclusion\"]}\\n```'}, template='\\n             Answer the user query and generate the response based on the following formatting instructions\\n\\n             Format Instructions:\\n             {format_instructions}\\n\\n             Query:\\n             {query}\\n            ')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7151641b5210>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x715164285190>, root_client=<openai.OpenAI object at 0x7151649d4990>, root_async_client=<openai.AsyncOpenAI object at 0x715164fcf690>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| JsonOutputParser(pydantic_object=<class '__main__.QueryResponse'>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a simple LCEL chain to take the prompt, pass it to the LLM, enforce response format using the parser\n",
    "chain = (prompt\n",
    "              |\n",
    "            chatgpt\n",
    "              |\n",
    "            parser)\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3dlBUHh7682",
    "outputId": "854fb56c-b230-4528-d4dd-85ad6acb8888"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Tell me about commercial real estate'},\n",
       " {'query': 'Tell me about Generative AI'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_queries = [\n",
    "    \"Tell me about commercial real estate\",\n",
    "    \"Tell me about Generative AI\"\n",
    "]\n",
    "\n",
    "topic_queries_formatted = [{\"query\": topic}\n",
    "                    for topic in topic_queries]\n",
    "topic_queries_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnxspdUb8rSd"
   },
   "outputs": [],
   "source": [
    "responses = chain.map().invoke(topic_queries_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bLhLZnQi8xqq",
    "outputId": "ddffcb66-4478-441b-fe6a-69a61fbedea9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'description': 'Commercial real estate refers to properties used exclusively for business purposes, including office buildings, retail spaces, warehouses, and industrial properties.',\n",
       "  'pros': '1. Potential for high returns on investment.\\n2. Long-term leases provide stable income.\\n3. Diversification of investment portfolio.',\n",
       "  'cons': '1. Requires significant capital investment.\\n2. Market fluctuations can impact property values.\\n3. Management and maintenance can be complex and time-consuming.',\n",
       "  'conclusion': 'Investing in commercial real estate can be lucrative but comes with its own set of challenges.'},\n",
       " dict)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0], type(responses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "aJJMXDsV82Pd",
    "outputId": "1611a9bb-9126-4ca1-88e7-a4d8fbc889c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>conclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Commercial real estate refers to properties us...</td>\n",
       "      <td>1. Potential for high returns on investment.\\n...</td>\n",
       "      <td>1. Requires significant capital investment.\\n2...</td>\n",
       "      <td>Investing in commercial real estate can be luc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generative AI refers to algorithms that can ge...</td>\n",
       "      <td>1. Can create unique and diverse content quick...</td>\n",
       "      <td>1. May produce biased or inappropriate content...</td>\n",
       "      <td>Generative AI holds great potential but requir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  Commercial real estate refers to properties us...   \n",
       "1  Generative AI refers to algorithms that can ge...   \n",
       "\n",
       "                                                pros  \\\n",
       "0  1. Potential for high returns on investment.\\n...   \n",
       "1  1. Can create unique and diverse content quick...   \n",
       "\n",
       "                                                cons  \\\n",
       "0  1. Requires significant capital investment.\\n2...   \n",
       "1  1. May produce biased or inappropriate content...   \n",
       "\n",
       "                                          conclusion  \n",
       "0  Investing in commercial real estate can be luc...  \n",
       "1  Generative AI holds great potential but requir...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(responses)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QCPgsG1r3d_g",
    "outputId": "78003d03-b7bb-4664-9231-67bddefc9613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description:\n",
      "Commercial real estate refers to properties used exclusively for business purposes, including office buildings, retail spaces, warehouses, and industrial properties.\n",
      "\n",
      "pros:\n",
      "1. Potential for high returns on investment.\n",
      "2. Long-term leases provide stable income.\n",
      "3. Diversification of investment portfolio.\n",
      "\n",
      "cons:\n",
      "1. Requires significant capital investment.\n",
      "2. Market fluctuations can impact property values.\n",
      "3. Management and maintenance can be complex and time-consuming.\n",
      "\n",
      "conclusion:\n",
      "Investing in commercial real estate can be lucrative but comes with its own set of challenges.\n",
      "\n",
      "-----\n",
      "description:\n",
      "Generative AI refers to algorithms that can generate new content, such as text, images, or music, based on training data.\n",
      "\n",
      "pros:\n",
      "1. Can create unique and diverse content quickly.\n",
      "2. Enhances creativity by providing new ideas and perspectives.\n",
      "3. Automates repetitive tasks, saving time and resources.\n",
      "\n",
      "cons:\n",
      "1. May produce biased or inappropriate content based on training data.\n",
      "2. Can lead to misinformation if not properly monitored.\n",
      "3. Ethical concerns regarding authorship and ownership of generated content.\n",
      "\n",
      "conclusion:\n",
      "Generative AI holds great potential but requires careful management to mitigate its risks.\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for response in responses:\n",
    "  for k,v in response.items():\n",
    "    print(f\"{k}:\\n{v}\\n\")\n",
    "  print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6PZ6XE8IX8B"
   },
   "source": [
    "### CommaSeparatedListOutputParser\n",
    "\n",
    "This output parser can be used when you want to return a list of comma-separated items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "KsXC0ij886pg",
    "outputId": "b8253b04-7cbf-4843-c844-9f75dea38470"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.comma_separated_list import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bzt_1I48-JEt",
    "outputId": "cee64284-baba-4226-c057-1ed1d973f03b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['format_instructions'], input_types={}, partial_variables={}, template='\\n             Create a list of 5 different ways in which Generative AI can be used\\n\\n             Output format instructions:\\n             {format_instructions}\\n             ')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "prompt_txt = \"\"\"\n",
    "             Create a list of 5 different ways in which Generative AI can be used\n",
    "\n",
    "             Output format instructions:\n",
    "             {format_instructions}\n",
    "             \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=prompt_txt)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1znuijS_Gds",
    "outputId": "4c1fd37e-ba58-4b27-a189-144dedb77103"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Content creation',\n",
       " 'Personalized marketing',\n",
       " 'Game design',\n",
       " 'Drug discovery',\n",
       " 'Virtual assistants']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a simple LLM Chain - more on this later\n",
    "llm_chain = (prompt\n",
    "              |\n",
    "            chatgpt\n",
    "              |\n",
    "            output_parser)\n",
    "\n",
    "# run the chain\n",
    "response = llm_chain.invoke({'format_instructions': format_instructions})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dzm72WA_Jzxv",
    "outputId": "330ba07b-59ae-4123-90bc-c46447d4fbe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
